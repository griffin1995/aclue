name: 🏎️ Performance Monitoring

on:
  schedule:
    # Run performance monitoring every 4 hours
    - cron: '0 */4 * * *'
  workflow_dispatch:
    inputs:
      monitoring_intensity:
        description: 'Performance monitoring intensity'
        required: true
        default: 'standard'
        type: choice
        options:
          - light
          - standard
          - comprehensive
      target_environment:
        description: 'Target environment to monitor'
        required: true
        default: 'production'
        type: choice
        options:
          - production
          - staging
          - development

env:
  # Performance thresholds
  MAX_RESPONSE_TIME: 3000  # milliseconds
  MIN_LIGHTHOUSE_SCORE: 80
  MAX_LOAD_TIME: 5000     # milliseconds

  # Monitoring configuration
  PERFORMANCE_TIMEOUT: 900  # 15 minutes
  CONCURRENT_USERS: 10
  TEST_DURATION: 60        # seconds

permissions:
  contents: read
  issues: write

jobs:
  # ================================================================
  # PERFORMANCE MONITORING SETUP
  # ================================================================

  performance-setup:
    name: 🔧 Setup Performance Monitoring
    runs-on: ubuntu-latest
    timeout-minutes: 5

    outputs:
      monitoring_intensity: ${{ steps.config.outputs.monitoring_intensity }}
      target_urls: ${{ steps.config.outputs.target_urls }}
      lighthouse_config: ${{ steps.config.outputs.lighthouse_config }}

    steps:
      - name: ⚙️ Configure Monitoring Parameters
        id: config
        run: |
          # Set monitoring intensity
          if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            intensity="${{ github.event.inputs.monitoring_intensity }}"
            environment="${{ github.event.inputs.target_environment }}"
          else
            intensity="standard"
            environment="production"
          fi

          echo "monitoring_intensity=$intensity" >> $GITHUB_OUTPUT

          # Configure target URLs based on environment
          case "$environment" in
            "production")
              frontend_url="https://aclue.app"
              backend_url="https://aclue-backend-production.up.railway.app"
              ;;
            "staging")
              frontend_url="https://staging.aclue.app"
              backend_url="https://aclue-backend-staging.up.railway.app"
              ;;
            "development")
              frontend_url="http://localhost:3000"
              backend_url="http://localhost:8000"
              ;;
          esac

          # Create target URLs JSON
          target_urls=$(cat << EOF
          {
            "frontend": "$frontend_url",
            "backend": "$backend_url",
            "environment": "$environment"
          }
          EOF
          )

          echo "target_urls=$(echo "$target_urls" | jq -c .)" >> $GITHUB_OUTPUT

          # Configure Lighthouse settings based on intensity
          case "$intensity" in
            "light")
              lighthouse_config='{"throttling":"simulated3G","formFactor":"mobile","onlyCategories":["performance"]}'
              ;;
            "standard")
              lighthouse_config='{"throttling":"simulated3G","formFactor":"desktop","onlyCategories":["performance","accessibility","best-practices"]}'
              ;;
            "comprehensive")
              lighthouse_config='{"throttling":"applied4G","formFactor":"desktop","onlyCategories":["performance","accessibility","best-practices","seo","pwa"]}'
              ;;
          esac

          echo "lighthouse_config=$lighthouse_config" >> $GITHUB_OUTPUT

      - name: 📊 Display Monitoring Configuration
        run: |
          echo "### 🏎️ Performance Monitoring Configuration" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Parameter | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Intensity | ${{ steps.config.outputs.monitoring_intensity }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Environment | $(echo '${{ steps.config.outputs.target_urls }}' | jq -r '.environment') |" >> $GITHUB_STEP_SUMMARY
          echo "| Frontend URL | $(echo '${{ steps.config.outputs.target_urls }}' | jq -r '.frontend') |" >> $GITHUB_STEP_SUMMARY
          echo "| Backend URL | $(echo '${{ steps.config.outputs.target_urls }}' | jq -r '.backend') |" >> $GITHUB_STEP_SUMMARY

  # ================================================================
  # LIGHTHOUSE PERFORMANCE AUDIT
  # ================================================================

  lighthouse-audit:
    name: 🏗️ Lighthouse Performance Audit
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: performance-setup

    steps:
      - name: 🔍 Checkout Repository
        uses: actions/checkout@v4

      - name: 📦 Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18.20.8'

      - name: 🏗️ Install Lighthouse CLI
        run: |
          npm install -g @lhci/cli lighthouse

      - name: 🔍 Extract Target URLs
        id: urls
        run: |
          echo "frontend_url=$(echo '${{ needs.performance-setup.outputs.target_urls }}' | jq -r '.frontend')" >> $GITHUB_OUTPUT
          echo "backend_url=$(echo '${{ needs.performance-setup.outputs.target_urls }}' | jq -r '.backend')" >> $GITHUB_OUTPUT

      - name: 🏗️ Run Lighthouse Audit - Frontend
        run: |
          mkdir -p lighthouse-results

          # Configure Lighthouse options
          lighthouse_config='${{ needs.performance-setup.outputs.lighthouse_config }}'
          throttling=$(echo "$lighthouse_config" | jq -r '.throttling')
          form_factor=$(echo "$lighthouse_config" | jq -r '.formFactor')
          categories=$(echo "$lighthouse_config" | jq -r '.onlyCategories | join(",")')

          # Run Lighthouse audit
          lighthouse \
            "${{ steps.urls.outputs.frontend_url }}" \
            --output=json \
            --output=html \
            --output-path=lighthouse-results/frontend-report \
            --chrome-flags="--headless --no-sandbox --disable-dev-shm-usage" \
            --throttling-method=simulate \
            --throttling.$throttling \
            --form-factor=$form_factor \
            --only-categories=$categories \
            --max-wait-for-load=30000

      - name: 📊 Analyze Lighthouse Results
        id: lighthouse_analysis
        run: |
          if [[ -f "lighthouse-results/frontend-report.json" ]]; then
            # Extract scores
            performance_score=$(jq '.categories.performance.score * 100' lighthouse-results/frontend-report.json)
            accessibility_score=$(jq '.categories.accessibility.score * 100 // 0' lighthouse-results/frontend-report.json)
            best_practices_score=$(jq '.categories["best-practices"].score * 100 // 0' lighthouse-results/frontend-report.json)

            # Extract metrics
            first_paint=$(jq '.audits["first-contentful-paint"].numericValue' lighthouse-results/frontend-report.json)
            largest_paint=$(jq '.audits["largest-contentful-paint"].numericValue' lighthouse-results/frontend-report.json)
            cumulative_shift=$(jq '.audits["cumulative-layout-shift"].numericValue' lighthouse-results/frontend-report.json)
            speed_index=$(jq '.audits["speed-index"].numericValue' lighthouse-results/frontend-report.json)

            echo "performance_score=$performance_score" >> $GITHUB_OUTPUT
            echo "accessibility_score=$accessibility_score" >> $GITHUB_OUTPUT
            echo "best_practices_score=$best_practices_score" >> $GITHUB_OUTPUT
            echo "first_paint=$first_paint" >> $GITHUB_OUTPUT
            echo "largest_paint=$largest_paint" >> $GITHUB_OUTPUT
            echo "cumulative_shift=$cumulative_shift" >> $GITHUB_OUTPUT
            echo "speed_index=$speed_index" >> $GITHUB_OUTPUT

            # Check if scores meet thresholds
            if (( $(echo "$performance_score >= $MIN_LIGHTHOUSE_SCORE" | bc -l) )); then
              echo "performance_status=PASS" >> $GITHUB_OUTPUT
            else
              echo "performance_status=FAIL" >> $GITHUB_OUTPUT
            fi

            # Generate summary
            echo "### 🏗️ Lighthouse Performance Results" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "| Metric | Score | Status |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|-------|--------|" >> $GITHUB_STEP_SUMMARY
            echo "| Performance | ${performance_score}% | $([ $(echo "$performance_score >= $MIN_LIGHTHOUSE_SCORE" | bc -l) -eq 1 ] && echo "✅" || echo "❌") |" >> $GITHUB_STEP_SUMMARY
            echo "| Accessibility | ${accessibility_score}% | $([ $(echo "$accessibility_score >= 80" | bc -l) -eq 1 ] && echo "✅" || echo "⚠️") |" >> $GITHUB_STEP_SUMMARY
            echo "| Best Practices | ${best_practices_score}% | $([ $(echo "$best_practices_score >= 80" | bc -l) -eq 1 ] && echo "✅" || echo "⚠️") |" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "| Core Web Vital | Value | Threshold | Status |" >> $GITHUB_STEP_SUMMARY
            echo "|----------------|-------|-----------|--------|" >> $GITHUB_STEP_SUMMARY
            echo "| First Contentful Paint | ${first_paint}ms | <2500ms | $([ $(echo "$first_paint <= 2500" | bc -l) -eq 1 ] && echo "✅" || echo "❌") |" >> $GITHUB_STEP_SUMMARY
            echo "| Largest Contentful Paint | ${largest_paint}ms | <4000ms | $([ $(echo "$largest_paint <= 4000" | bc -l) -eq 1 ] && echo "✅" || echo "❌") |" >> $GITHUB_STEP_SUMMARY
            echo "| Cumulative Layout Shift | ${cumulative_shift} | <0.25 | $([ $(echo "$cumulative_shift <= 0.25" | bc -l) -eq 1 ] && echo "✅" || echo "❌") |" >> $GITHUB_STEP_SUMMARY
            echo "| Speed Index | ${speed_index}ms | <4300ms | $([ $(echo "$speed_index <= 4300" | bc -l) -eq 1 ] && echo "✅" || echo "❌") |" >> $GITHUB_STEP_SUMMARY

          else
            echo "performance_status=ERROR" >> $GITHUB_OUTPUT
            echo "### ❌ Lighthouse Audit Failed" >> $GITHUB_STEP_SUMMARY
            echo "Could not generate performance report" >> $GITHUB_STEP_SUMMARY
          fi

      - name: 📋 Upload Lighthouse Results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: lighthouse-performance-results
          path: lighthouse-results/
          retention-days: 30

  # ================================================================
  # API PERFORMANCE TESTING
  # ================================================================

  api-performance:
    name: ⚡ API Performance Testing
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: performance-setup

    steps:
      - name: 🔍 Checkout Repository
        uses: actions/checkout@v4

      - name: 📦 Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18.20.8'

      - name: ⚡ Install Artillery
        run: npm install -g artillery

      - name: 🔍 Extract Backend URL
        id: backend
        run: |
          echo "backend_url=$(echo '${{ needs.performance-setup.outputs.target_urls }}' | jq -r '.backend')" >> $GITHUB_OUTPUT

      - name: ⚡ Create Artillery Configuration
        run: |
          mkdir -p performance-results

          # Create Artillery test configuration
          cat > performance-results/artillery-config.yml << EOF
          config:
            target: '${{ steps.backend.outputs.backend_url }}'
            phases:
              - duration: 60
                arrivalRate: ${{ env.CONCURRENT_USERS }}
                name: "Sustained load"
            processor: "./processor.js"

          scenarios:
            - name: "Health check"
              weight: 30
              flow:
                - get:
                    url: "/health"
                    expect:
                      - statusCode: 200
                      - contentType: "application/json"
                    capture:
                      - json: "$.status"
                        as: "health_status"

            - name: "API endpoints"
              weight: 50
              flow:
                - get:
                    url: "/api/v1/products/"
                    expect:
                      - statusCode: 200
                    capture:
                      - json: "$[0].id"
                        as: "product_id"
                - get:
                    url: "/api/v1/categories/"
                    expect:
                      - statusCode: 200

            - name: "Auth endpoints"
              weight: 20
              flow:
                - get:
                    url: "/api/v1/auth/health"
                    expect:
                      - statusCode: 200
          EOF

          # Create processor for custom logic
          cat > performance-results/processor.js << 'EOF'
          module.exports = {
            logResponse: function(requestParams, response, context, ee, next) {
              console.log(`Response time: ${response.timings.phases.total}ms`);
              return next();
            }
          };
          EOF

      - name: ⚡ Run Artillery Load Test
        run: |
          cd performance-results

          # Run Artillery test with JSON output
          artillery run artillery-config.yml --output artillery-report.json

          # Generate HTML report
          artillery report artillery-report.json --output artillery-report.html

      - name: 📊 Analyze API Performance Results
        id: api_analysis
        run: |
          cd performance-results

          if [[ -f "artillery-report.json" ]]; then
            # Extract key metrics
            avg_response_time=$(jq '.aggregate.latency.mean' artillery-report.json)
            p95_response_time=$(jq '.aggregate.latency.p95' artillery-report.json)
            p99_response_time=$(jq '.aggregate.latency.p99' artillery-report.json)
            requests_per_second=$(jq '.aggregate.rps.mean' artillery-report.json)
            error_rate=$(jq '.aggregate.counters."vusers.failed_requests" // 0' artillery-report.json)
            total_requests=$(jq '.aggregate.counters."http.requests"' artillery-report.json)

            echo "avg_response_time=$avg_response_time" >> $GITHUB_OUTPUT
            echo "p95_response_time=$p95_response_time" >> $GITHUB_OUTPUT
            echo "p99_response_time=$p99_response_time" >> $GITHUB_OUTPUT
            echo "requests_per_second=$requests_per_second" >> $GITHUB_OUTPUT
            echo "error_rate=$error_rate" >> $GITHUB_OUTPUT
            echo "total_requests=$total_requests" >> $GITHUB_OUTPUT

            # Calculate error percentage
            if [[ $total_requests -gt 0 ]]; then
              error_percentage=$(echo "scale=2; ($error_rate * 100) / $total_requests" | bc)
            else
              error_percentage=100
            fi

            echo "error_percentage=$error_percentage" >> $GITHUB_OUTPUT

            # Check performance thresholds
            if (( $(echo "$avg_response_time <= $MAX_RESPONSE_TIME" | bc -l) )) && (( $(echo "$error_percentage <= 5" | bc -l) )); then
              echo "api_performance_status=PASS" >> $GITHUB_OUTPUT
            else
              echo "api_performance_status=FAIL" >> $GITHUB_OUTPUT
            fi

            # Generate summary
            echo "### ⚡ API Performance Results" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "| Metric | Value | Threshold | Status |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|-------|-----------|--------|" >> $GITHUB_STEP_SUMMARY
            echo "| Average Response Time | ${avg_response_time}ms | <${MAX_RESPONSE_TIME}ms | $([ $(echo "$avg_response_time <= $MAX_RESPONSE_TIME" | bc -l) -eq 1 ] && echo "✅" || echo "❌") |" >> $GITHUB_STEP_SUMMARY
            echo "| 95th Percentile | ${p95_response_time}ms | - | ℹ️ |" >> $GITHUB_STEP_SUMMARY
            echo "| 99th Percentile | ${p99_response_time}ms | - | ℹ️ |" >> $GITHUB_STEP_SUMMARY
            echo "| Requests/Second | ${requests_per_second} | - | ℹ️ |" >> $GITHUB_STEP_SUMMARY
            echo "| Error Rate | ${error_percentage}% | <5% | $([ $(echo "$error_percentage <= 5" | bc -l) -eq 1 ] && echo "✅" || echo "❌") |" >> $GITHUB_STEP_SUMMARY
            echo "| Total Requests | ${total_requests} | - | ℹ️ |" >> $GITHUB_STEP_SUMMARY

          else
            echo "api_performance_status=ERROR" >> $GITHUB_OUTPUT
            echo "### ❌ API Performance Test Failed" >> $GITHUB_STEP_SUMMARY
            echo "Could not generate performance report" >> $GITHUB_STEP_SUMMARY
          fi

      - name: 📋 Upload API Performance Results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: api-performance-results
          path: performance-results/
          retention-days: 30

  # ================================================================
  # RESOURCE MONITORING
  # ================================================================

  resource-monitoring:
    name: 📊 Resource Usage Monitoring
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: performance-setup

    steps:
      - name: 🔍 Monitor External Resources
        run: |
          mkdir -p resource-monitoring

          # Extract URLs
          frontend_url=$(echo '${{ needs.performance-setup.outputs.target_urls }}' | jq -r '.frontend')
          backend_url=$(echo '${{ needs.performance-setup.outputs.target_urls }}' | jq -r '.backend')

          echo "### 📊 Resource Monitoring Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Monitor frontend resources
          echo "#### Frontend Resource Analysis" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Get page size and resources
          frontend_response=$(curl -s -w "%{size_download}|%{time_total}|%{num_connects}" "$frontend_url" -o resource-monitoring/frontend.html)
          IFS='|' read -r page_size load_time connections <<< "$frontend_response"

          echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Page Size | ${page_size} bytes |" >> $GITHUB_STEP_SUMMARY
          echo "| Load Time | ${load_time}s |" >> $GITHUB_STEP_SUMMARY
          echo "| Connections | ${connections} |" >> $GITHUB_STEP_SUMMARY

          # Monitor backend API response times
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "#### Backend API Response Times" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          api_endpoints=(
            "/health"
            "/api/v1/products/"
            "/api/v1/categories/"
          )

          echo "| Endpoint | Response Time | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|---------------|--------|" >> $GITHUB_STEP_SUMMARY

          for endpoint in "${api_endpoints[@]}"; do
            response_time=$(curl -w "%{time_total}" -s -o /dev/null "$backend_url$endpoint")
            status_code=$(curl -w "%{http_code}" -s -o /dev/null "$backend_url$endpoint")

            if [[ "$status_code" == "200" ]]; then
              status_icon="✅"
            else
              status_icon="❌"
            fi

            echo "| $endpoint | ${response_time}s | $status_icon |" >> $GITHUB_STEP_SUMMARY
          done

      - name: 📋 Upload Resource Monitoring Results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: resource-monitoring-results
          path: resource-monitoring/
          retention-days: 7

  # ================================================================
  # PERFORMANCE REPORT AGGREGATION
  # ================================================================

  performance-report:
    name: 📈 Performance Report
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: [performance-setup, lighthouse-audit, api-performance, resource-monitoring]
    if: always()

    steps:
      - name: 📥 Download Performance Results
        uses: actions/download-artifact@v3
        with:
          path: all-performance-results/

      - name: 📈 Generate Performance Summary
        run: |
          mkdir -p performance-summary

          # Initialize variables with defaults
          lighthouse_score="${{ needs.lighthouse-audit.outputs.performance_score || 'N/A' }}"
          lighthouse_status="${{ needs.lighthouse-audit.outputs.performance_status || 'ERROR' }}"
          api_response_time="${{ needs.api-performance.outputs.avg_response_time || 'N/A' }}"
          api_status="${{ needs.api-performance.outputs.api_performance_status || 'ERROR' }}"
          error_rate="${{ needs.api-performance.outputs.error_percentage || 'N/A' }}"

          # Determine overall performance status
          if [[ "$lighthouse_status" == "PASS" && "$api_status" == "PASS" ]]; then
            overall_status="EXCELLENT"
            status_emoji="🚀"
            status_color="good"
          elif [[ "$lighthouse_status" == "PASS" || "$api_status" == "PASS" ]]; then
            overall_status="GOOD"
            status_emoji="✅"
            status_color="warning"
          else
            overall_status="NEEDS_IMPROVEMENT"
            status_emoji="⚠️"
            status_color="danger"
          fi

          # Create performance summary JSON
          cat > performance-summary/performance-summary.json << EOF
          {
            "timestamp": "$(date -Iseconds)",
            "monitoring_intensity": "${{ needs.performance-setup.outputs.monitoring_intensity }}",
            "environment": $(echo '${{ needs.performance-setup.outputs.target_urls }}' | jq '.environment'),
            "overall_status": "$overall_status",
            "lighthouse": {
              "performance_score": $lighthouse_score,
              "status": "$lighthouse_status"
            },
            "api": {
              "avg_response_time": $api_response_time,
              "error_rate": $error_rate,
              "status": "$api_status"
            },
            "github": {
              "run_id": "${{ github.run_id }}",
              "sha": "${{ github.sha }}",
              "ref": "${{ github.ref }}"
            }
          }
          EOF

          # Update GitHub Step Summary
          echo "### 📈 Overall Performance Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Overall Status**: $status_emoji $overall_status" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Component | Status | Key Metric |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|--------|------------|" >> $GITHUB_STEP_SUMMARY
          echo "| Frontend (Lighthouse) | $lighthouse_status | ${lighthouse_score}% |" >> $GITHUB_STEP_SUMMARY
          echo "| API Performance | $api_status | ${api_response_time}ms avg |" >> $GITHUB_STEP_SUMMARY
          echo "| Error Rate | $([ "$error_rate" != "N/A" ] && [ $(echo "$error_rate <= 5" | bc -l 2>/dev/null || echo 0) -eq 1 ] && echo "✅" || echo "⚠️") | ${error_rate}% |" >> $GITHUB_STEP_SUMMARY

          echo "OVERALL_STATUS=$overall_status" >> $GITHUB_ENV
          echo "STATUS_COLOR=$status_color" >> $GITHUB_ENV
          echo "STATUS_EMOJI=$status_emoji" >> $GITHUB_ENV

      - name: 📋 Upload Performance Summary
        uses: actions/upload-artifact@v3
        with:
          name: performance-summary-report
          path: performance-summary/
          retention-days: 90

      - name: 🔔 Send Performance Notification
        if: env.SLACK_WEBHOOK != ''
        env:
          SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK }}
        run: |
          # Send Slack notification with performance results
          curl -X POST -H 'Content-type: application/json' \
            --data "{
              \"attachments\": [
                {
                  \"color\": \"$STATUS_COLOR\",
                  \"title\": \"$STATUS_EMOJI Aclue Performance Monitoring Report\",
                  \"fields\": [
                    {\"title\": \"Overall Status\", \"value\": \"$OVERALL_STATUS\", \"short\": true},
                    {\"title\": \"Environment\", \"value\": \"$(echo '${{ needs.performance-setup.outputs.target_urls }}' | jq -r '.environment')\", \"short\": true},
                    {\"title\": \"Lighthouse Score\", \"value\": \"${{ needs.lighthouse-audit.outputs.performance_score || 'N/A' }}%\", \"short\": true},
                    {\"title\": \"API Response Time\", \"value\": \"${{ needs.api-performance.outputs.avg_response_time || 'N/A' }}ms\", \"short\": true}
                  ],
                  \"footer\": \"GitHub Actions • Aclue Performance Monitor\",
                  \"ts\": $(date +%s),
                  \"actions\": [
                    {
                      \"type\": \"button\",
                      \"text\": \"View Details\",
                      \"url\": \"${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}\"
                    }
                  ]
                }
              ]
            }" \
            $SLACK_WEBHOOK || echo "Failed to send performance notification"

      - name: 🚨 Create Performance Issue
        if: env.OVERALL_STATUS == 'NEEDS_IMPROVEMENT'
        uses: actions/github-script@v6
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `⚠️ Performance Degradation Detected - ${new Date().toISOString().split('T')[0]}`,
              body: `## Performance Monitoring Alert

            **Overall Status**: ${{ env.OVERALL_STATUS }}
            **Environment**: $(echo '${{ needs.performance-setup.outputs.target_urls }}' | jq -r '.environment')
            **Detection Time**: ${new Date().toISOString()}

            ### Performance Metrics

            | Component | Status | Value |
            |-----------|--------|-------|
            | Lighthouse Performance | ${{ needs.lighthouse-audit.outputs.performance_status || 'ERROR' }} | ${{ needs.lighthouse-audit.outputs.performance_score || 'N/A' }}% |
            | API Performance | ${{ needs.api-performance.outputs.api_performance_status || 'ERROR' }} | ${{ needs.api-performance.outputs.avg_response_time || 'N/A' }}ms |
            | Error Rate | - | ${{ needs.api-performance.outputs.error_percentage || 'N/A' }}% |

            ### Recommended Actions
            - [ ] Review Lighthouse audit results for frontend optimization opportunities
            - [ ] Analyze API response times and database query performance
            - [ ] Check server resource utilization and scaling requirements
            - [ ] Review recent deployments for performance regressions

            **Workflow Run**: [${{ github.run_id }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})`,
              labels: ['performance', 'monitoring', 'needs-investigation']
            })

  # ================================================================
  # PERFORMANCE ALERTS
  # ================================================================

  performance-alerts:
    name: 🚨 Performance Alerts
    runs-on: ubuntu-latest
    needs: [lighthouse-audit, api-performance, performance-report]
    if: always() && (needs.lighthouse-audit.outputs.performance_status == 'FAIL' || needs.api-performance.outputs.api_performance_status == 'FAIL')

    steps:
      - name: 🚨 Critical Performance Alert
        run: |
          echo "### 🚨 CRITICAL PERFORMANCE ALERT" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Performance thresholds have been exceeded!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Immediate Action Required**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [[ "${{ needs.lighthouse-audit.outputs.performance_status }}" == "FAIL" ]]; then
            echo "- ❌ **Frontend Performance**: Score ${{ needs.lighthouse-audit.outputs.performance_score }}% (threshold: ${{ env.MIN_LIGHTHOUSE_SCORE }}%)" >> $GITHUB_STEP_SUMMARY
          fi

          if [[ "${{ needs.api-performance.outputs.api_performance_status }}" == "FAIL" ]]; then
            echo "- ❌ **API Performance**: Response time ${{ needs.api-performance.outputs.avg_response_time }}ms (threshold: ${{ env.MAX_RESPONSE_TIME }}ms)" >> $GITHUB_STEP_SUMMARY
          fi

          exit 1